{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc8d0a72-882f-4d53-80a8-5c6c957384e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORICAL:  ['patient_race', 'payer_type', 'patient_state', 'breast_cancer_diagnosis_code', 'metastatic_cancer_diagnosis_code', 'patient_zip3']\n",
      "NUMERICAL:  ['patient_age', 'patient_zip3']\n",
      "\n",
      "AFTER PREPROCESSING:\n",
      "(12906, 7)\n",
      "(5792, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "path = 'training.csv' # path to the file we're looking at. \n",
    "# in this case the file is in the same folder as my notebook, so I don't need to specify the full path\n",
    "train_df = pd.read_csv(path)\n",
    "\n",
    "path = 'test.csv'\n",
    "test_df = pd.read_csv(path)\n",
    "\n",
    "# want to keep info about the patient themselves also some specifc regional data that could have an impact on the patient's health\n",
    "# i'm excluded the demographic info that's not a characteristic of the patients themselves\n",
    "cols = [\n",
    "    'patient_race',\n",
    "    'payer_type',\n",
    "    'patient_state',\n",
    "    'patient_age',\n",
    "    # 'patient_gender',\n",
    "    'breast_cancer_diagnosis_code',\n",
    "    'metastatic_cancer_diagnosis_code',\n",
    "    'patient_zip3'\n",
    "]\n",
    "\n",
    "train_df_simple = train_df[cols]\n",
    "test_df_simple = test_df[cols]\n",
    "\n",
    "# fill in nulls\n",
    "categorical_cols = train_df_simple.select_dtypes(include=['object']).columns.to_list() + ['patient_zip3']\n",
    "numerical_cols = train_df_simple.select_dtypes(exclude=['object']).columns.to_list()\n",
    "\n",
    "print('CATEGORICAL: ', categorical_cols)\n",
    "print('NUMERICAL: ', numerical_cols)\n",
    "\n",
    "# median for numerical - zip3 is technically categorical so skip it for now\n",
    "for c in numerical_cols :\n",
    "    if c == 'patient_zip3':\n",
    "        continue\n",
    "    train_df_simple[c].fillna(value=train_df_simple[c].median(), inplace=True)\n",
    "    test_df_simple[c].fillna(value=test_df_simple[c].median(), inplace=True)\n",
    "    \n",
    "# 'Unknown' for categorical (the rest)\n",
    "for c in categorical_cols:\n",
    "    train_df_simple[c].fillna('Unknown', inplace=True)\n",
    "    test_df_simple[c].fillna('Unknown', inplace=True)\n",
    "    \n",
    "# #### no preprocessing... let's see if catboost like it ####\n",
    "# X_train, y_train, X_test = train_df_simple, train_df['DiagPeriodL90D'], test_df_simple\n",
    "\n",
    "# encode categorical variables\n",
    "# ordinal encoder - fit and transform on train df - ordinal encoder will label each category from 0 to n. This is the opposite of one-hot encoding, which will add a column for each category\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value = -1)\n",
    "# for each categorical col, fit the encoder on train data, encode the train data, and encode the test data\n",
    "for c in categorical_cols:\n",
    "    train_df_simple[c] = encoder.fit_transform(train_df_simple[[c]])\n",
    "    test_df_simple[c] = encoder.transform(test_df_simple[[c]])\n",
    "\n",
    "# train_df_simple = pd.get_dummies(train_df_simple, columns=categorical_cols)  \n",
    "# test_df_simple = pd.get_dummies(test_df_simple, columns=categorical_cols) \n",
    "\n",
    "# # get list of missing cols in test data \n",
    "# missing_cols = [x for x in train_df_simple.columns if x not in test_df_simple.columns and x != 'DiagPeriodL90D']\n",
    "\n",
    "# # add these cols with default value = 0\n",
    "# for c in missing_cols:\n",
    "#     test_df_simple[c] = 0\n",
    "    \n",
    "# # reorder the columns to make sure the test and train are the same\n",
    "# test_df_simple = test_df_simple[train_df_simple.columns]\n",
    "\n",
    "\n",
    "print('\\nAFTER PREPROCESSING:')\n",
    "print(train_df_simple.shape)\n",
    "print(test_df_simple.shape)\n",
    "\n",
    "# standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_df_simple)\n",
    "X_test = scaler.transform(test_df_simple)\n",
    "\n",
    "y_train = train_df['DiagPeriodL90D']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff230a1e-f3cf-4d79-82c3-05120af582f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808a6e19-7a84-473a-9c27-b68401cc4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc4eadc-0030-40b3-bc51-5169072088fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- ITERATION 0 --------------\n",
      "\n",
      "Best Parameters:  {'random_strength': 0.5, 'loss_function': 'Logloss', 'learning_rate': 0.05, 'iterations': 1000, 'eval_metric': 'AUC', 'depth': 2}\n",
      "\n",
      "Best Accuracy: 0.81349760\n",
      "\n",
      "---------------- ITERATION 1 --------------\n",
      "\n",
      "Best Parameters:  {'random_strength': 1.0, 'loss_function': 'Logloss', 'learning_rate': 0.1, 'iterations': 500, 'eval_metric': 'AUC', 'depth': 2}\n",
      "\n",
      "Best Accuracy: 0.81342011\n",
      "\n",
      "---------------- ITERATION 2 --------------\n",
      "\n",
      "Best Parameters:  {'random_strength': 0.5, 'loss_function': 'Logloss', 'learning_rate': 0.05, 'iterations': 1000, 'eval_metric': 'AUC', 'depth': 2}\n",
      "\n",
      "Best Accuracy: 0.81349760\n",
      "\n",
      "---------------- ITERATION 3 --------------\n",
      "\n",
      "Best Parameters:  {'random_strength': 0.1, 'loss_function': 'Logloss', 'learning_rate': 0.01, 'iterations': 1000, 'eval_metric': 'Logloss', 'depth': 4}\n",
      "\n",
      "Best Accuracy: 0.81318766\n",
      "\n",
      "---------------- ITERATION 4 --------------\n",
      "\n",
      "Best Parameters:  {'random_strength': 1.0, 'loss_function': 'Logloss', 'learning_rate': 0.05, 'iterations': 1000, 'eval_metric': 'AUC', 'depth': 2}\n",
      "\n",
      "Best Accuracy: 0.81334263\n",
      "\n",
      "\n",
      "Elapsed Time: 13 minutes and 20.472672939300537 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # start timer\n",
    "\n",
    "# Define hyperparameters - this will depend on the model. you can refer to the docs or use ChatGPT to spit out different parameter tests\n",
    "# these are arbitrary values I got from ChatGPT\n",
    "param_grid = {\n",
    "    'iterations': [500, 1000],\n",
    "    'learning_rate':  [0.01, 0.05, 0.1],\n",
    "    'depth': [2, 4, 6 ], # , 8],\n",
    "    # 'l2_leaf_reg': [1, 5, 10],\n",
    "    'loss_function': ['Logloss'], # 'border_count': [5, 10, 20, 50, 100],\n",
    "    'random_strength': [0.1, 0.5, 1.0],\n",
    "    # 'bagging_temperature': [0.2, 0.5, 0.8],\n",
    "    'eval_metric' : ['AUC', 'Logloss'],\n",
    "    # 'cat_features' : [categorical_cols] # comment if encoding categorical variables\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(silent=True)\n",
    "\n",
    "# Number of iterations for RandomizedSearchCV\n",
    "num_iterations = 5\n",
    "test_predictions_list = []\n",
    "\n",
    "# Perform multiple iterations of RandomizedSearchCV\n",
    "for i in range(num_iterations):\n",
    "    print(\"---------------- ITERATION %d --------------\" % i)\n",
    "    # RandomizedSearchCV to find the best hyperparameters\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=15, cv=3, random_state=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    # get bets values\n",
    "    best_model = random_search.best_estimator_\n",
    "    test_predictions = best_model.predict_proba(X_test)[:,1]\n",
    "    # print best parameters and accuracy\n",
    "    print(\"\\nBest Parameters: \", random_search.best_params_)\n",
    "    print(\"\\nBest Accuracy: {:.8f}\\n\".format(random_search.best_score_))\n",
    "    # Append the test predictions to the list\n",
    "    test_predictions_list.append(test_predictions)\n",
    "    \n",
    "    \n",
    "    \n",
    "end_time = time.time() # end the timer\n",
    "elapsed_time_seconds = end_time - start_time\n",
    "print(f\"\\nElapsed Time: {int(elapsed_time_seconds // 60)} minutes and {elapsed_time_seconds % 60} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dc0fa04-dd55-4c9e-bd05-9b5040078288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters (standardizing):  {'random_strength': 0.5, 'learning_rate': 0.05, 'l2_leaf_reg': 5, 'iterations': 200, 'eval_metric': 'AUC', 'depth': 4, 'border_count': 100, 'bagging_temperature': 0.5}\n",
    "# Best Parameters:  {'random_strength': 0.5, 'learning_rate': 0.05, 'l2_leaf_reg': 5, 'iterations': 200, 'eval_metric': 'AUC', 'depth': 4, 'border_count': 100, 'bagging_temperature': 0.2}\n",
    "\n",
    "\n",
    "## ADDED BACK PATIENT_ZIP3\n",
    "\n",
    "## added back all params in grid\n",
    "\n",
    "## removed preprocessing steps\n",
    "\n",
    "## fixed preprocessing steps - ordinal encoding. instead of None replaced with Unknown\n",
    "\n",
    "## removed gender from features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85dcd51-4013-4f20-b36e-a10b6a0d5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81093585 0.79869847 0.76538146 ... 0.93318363 0.10393951 0.87487749]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>DiagPeriodL90D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573710</td>\n",
       "      <td>0.810936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593679</td>\n",
       "      <td>0.798698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184532</td>\n",
       "      <td>0.765381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447383</td>\n",
       "      <td>0.802683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687972</td>\n",
       "      <td>0.795524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>977076</td>\n",
       "      <td>0.845578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>922960</td>\n",
       "      <td>0.866911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>759690</td>\n",
       "      <td>0.933184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>911717</td>\n",
       "      <td>0.103940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>327597</td>\n",
       "      <td>0.874877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  DiagPeriodL90D\n",
       "0         573710        0.810936\n",
       "1         593679        0.798698\n",
       "2         184532        0.765381\n",
       "3         447383        0.802683\n",
       "4         687972        0.795524\n",
       "...          ...             ...\n",
       "5787      977076        0.845578\n",
       "5788      922960        0.866911\n",
       "5789      759690        0.933184\n",
       "5790      911717        0.103940\n",
       "5791      327597        0.874877\n",
       "\n",
       "[5792 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the mean/med of test set predictions across iterations\n",
    "mean_test_predictions =  np.median(test_predictions_list, axis=0)\n",
    "print(mean_test_predictions)\n",
    "\n",
    "# create df for submission\n",
    "sub_df = test_df[['patient_id']]\n",
    "sub_df['DiagPeriodL90D'] = mean_test_predictions\n",
    "\n",
    "# save the submission\n",
    "display(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3053785f-0c73-41a3-9bc3-f2a886f7c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('simplified_submission_cb_mean_' + str(iterations) + '.csv', index=False)\n",
    "iterations += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3adb1e-da41-4523-9843-7fcdae01d32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83709324-9d70-4cb3-add2-f305eec36498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60f697-ba95-45d0-af93-8d18366a8266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787174c2-43d8-4579-9a3c-5c0f71f9ec99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b566c5-f5e9-49d0-b2db-f8426741521f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b369c191-5bbc-4be7-8c98-10314cf0bbca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on fold: 0.7631865846450229 | accuracy on train: 0.7652966161665647\n",
      "accuracy on fold: 0.7678979514944677 | accuracy on train: 0.7621671236612236\n",
      "accuracy on fold: 0.7595383654150969 | accuracy on train: 0.7660074708981784\n",
      "[0.80135131 0.77071885 0.78559735 ... 0.89862395 0.10440774 0.86427718]\n"
     ]
    }
   ],
   "source": [
    "# try different method of k-fold \n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Step 1: Divide train set into 5 folds and train CatBoost classifier\n",
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=26)\n",
    "\n",
    "# Initialize an array to store test predictions from each fold\n",
    "test_predictions_list = []\n",
    "\n",
    "# params \n",
    "params = {\n",
    "    'silent': True,'random_strength': 0.1, 'loss_function': 'Logloss', 'learning_rate': 0.05, 'iterations': 1000, 'eval_metric': 'AUC', 'depth': 2\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize and train CatBoost model\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), use_best_model=True)\n",
    "    \n",
    "    # Step 2: Use test set to get predictions\n",
    "    test_predictions_fold = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # get prediction accuracy of the validation fold\n",
    "    fold_score = roc_auc_score(y_val_fold, model.predict(X_val_fold))\n",
    "    train_score = roc_auc_score(y_train_fold, model.predict(X_train_fold)) \n",
    "    print(f\"accuracy on fold: {fold_score} | accuracy on train: {train_score}\")\n",
    "\n",
    "    # Step 3: Append test predictions to the list\n",
    "    test_predictions_list.append(test_predictions_fold)\n",
    "    \n",
    "\n",
    "# Step 4: Get the mean of all 5 test predictions\n",
    "mean_test_predictions = np.mean(test_predictions_list, axis=0)\n",
    "print(mean_test_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82715ccf-6919-4b78-abd6-664bcd02108b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>DiagPeriodL90D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573710</td>\n",
       "      <td>0.802034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593679</td>\n",
       "      <td>0.775271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184532</td>\n",
       "      <td>0.778288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447383</td>\n",
       "      <td>0.793738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687972</td>\n",
       "      <td>0.823346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>977076</td>\n",
       "      <td>0.833914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>922960</td>\n",
       "      <td>0.871146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>759690</td>\n",
       "      <td>0.896733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>911717</td>\n",
       "      <td>0.106153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>327597</td>\n",
       "      <td>0.860847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  DiagPeriodL90D\n",
       "0         573710        0.802034\n",
       "1         593679        0.775271\n",
       "2         184532        0.778288\n",
       "3         447383        0.793738\n",
       "4         687972        0.823346\n",
       "...          ...             ...\n",
       "5787      977076        0.833914\n",
       "5788      922960        0.871146\n",
       "5789      759690        0.896733\n",
       "5790      911717        0.106153\n",
       "5791      327597        0.860847\n",
       "\n",
       "[5792 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create df for submission\n",
    "sub_df = test_df[['patient_id']]\n",
    "sub_df['DiagPeriodL90D'] = mean_test_predictions\n",
    "\n",
    "# save the submission\n",
    "display(sub_df)\n",
    "\n",
    "\n",
    "sub_df.to_csv('simplified_submission_cb_mean_kfold_' + str(iterations) + '.csv', index=False)\n",
    "iterations += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca67a79-90db-404a-9588-67911429c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will it help to use ordinal encoding cb_1 --> YES (less features works out better. however, it is dangerous to apply ordinal encoding to features such as race)\n",
    "\n",
    "# use kfold on the best parameters i've seen --> eh it's kinda the same (or worse)\n",
    "\n",
    "# will it help to bring back patient_zip3? --> it's the same. best i can do is 0.808\n",
    "\n",
    "# will it help to NOT encode categorical variables (catboost can handle non-encoded vals) --> NO\n",
    "\n",
    "# median? --> nah\n",
    "\n",
    "# take best accuract amongst iterations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256023b3-14e1-4d52-babd-14ceacf36d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ac52e-d461-47c5-8977-1e7fa2e3581f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e279924-457a-4b05-8b33-4c833a3c8aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a26889-4520-4df6-8831-66b86166cd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
